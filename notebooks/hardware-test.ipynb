{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911a4f68-b972-4e8f-9266-b4afec7e4bbe",
   "metadata": {},
   "source": [
    "# Comparing Workflow Performance on Different Backends \n",
    "\n",
    "As of now, JAX does not support the Apple GPU for hardware acceleration and computations will by default fall back to the CPU. TensorFlow and PyTorch both have Metal backend support for Apple GPUs, allowing better utilization of the M2 chip’s GPU. Tests below compare TF & Jax performance on both CPU & GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a040cd-f82d-48ba-9399-1f3c6ffe8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Setup on an M2 Mac\n",
    "\n",
    "# pip install tensorflow-macos\n",
    "# pip install tensorflow-metal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b16a4df-e6d7-4659-8564-3ac5c9bb5f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.2\n",
      "Is GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Verify if TensorFlow detects the GPU (Metal backend)\n",
    "print(\"Is GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e4989-0bc5-43c8-a229-380c07a91172",
   "metadata": {},
   "source": [
    "The memory growth setting allows TensorFlow to:\n",
    "\n",
    "- Allocate only the memory it needs, instead of reserving all GPU memory upfront.\n",
    "- Dynamically increase memory usage as the workload grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bdff7b-12aa-4f6d-9db7-d1df9db7ddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set memory growth for GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Set memory growth for GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3f7e4-e25b-4134-907c-1053ddff2b94",
   "metadata": {},
   "source": [
    "# TensorFlow CPU vs. GPU Test\n",
    "\n",
    "**A Note on Matrix Size Impact** \n",
    "\n",
    "For testing, larger matrices benefit GPU usage (i.e. the [10000, 10000] one listed below, while smaller ones [1000, 1000] may favor the CPU due to overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66860cd9-d3bf-4350-9fff-aaa17ad26808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 4.150007963180542\n",
      "GPU time: 0.025270938873291016\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Generate random matrices\n",
    "a = tf.random.normal([10000, 10000])\n",
    "b = tf.random.normal([10000, 10000])\n",
    "\n",
    "# Perform on CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    start = time.time()\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"CPU time:\", time.time() - start)\n",
    "\n",
    "# Perform on GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"GPU time:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7187b5-b15e-456d-8145-94664ab95027",
   "metadata": {},
   "source": [
    "# JAX Metal Test (Experimental)\n",
    "\n",
    "JAX uses lazy execution, meaning computations are deferred until explicitly needed (via .block_until_ready()), adding slight overhead compared to TensorFlow, which eagerly executes operations. \n",
    "\n",
    "[Apple Dev Docs](https://developer.apple.com/metal/jax/)\n",
    "\n",
    "Vastly slower execution on this one as of Nov 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b860c11-4c1d-45a4-a5fc-9e9698458676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX version: 0.4.35\n",
      "Metal device set to: Apple M2\n",
      "JAX is using device: METAL:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1731468564.655199  545268 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1731468564.655418  545268 service.cc:145] XLA service 0x600000524400 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731468564.655426  545268 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1731468564.656324  545268 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1731468564.656332  545268 mps_client.cc:384] XLA backend will use up to 15579430912 bytes on device 0 for SimpleAllocator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX computation time: 2.1954009532928467\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import time\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "\n",
    "# Check the device JAX is using\n",
    "print(f\"JAX is using device: {jax.devices()[0]}\")\n",
    "\n",
    "# Generate random matrices using jax.random\n",
    "key = random.PRNGKey(0)  # Create a random key\n",
    "a = random.normal(key, shape=(10000, 10000))\n",
    "b = random.normal(key, shape=(10000, 10000))\n",
    "\n",
    "# Perform matrix multiplication on JAX (using Metal GPU if available)\n",
    "start = time.time()\n",
    "c = jnp.dot(a, b).block_until_ready()  # Ensure computation finishes\n",
    "print(\"JAX computation time:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e60cb-f6c8-4a16-9698-e3e3305c1df2",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- TensorFlow’s Metal Backend delivers excellent GPU performance on M2 Macs.\n",
    "- JAX currently lacks full support for Metal, making it less competitive on Apple hardware.\n",
    "- TensorFlow outperforms JAX on the CPU due to its mature optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
